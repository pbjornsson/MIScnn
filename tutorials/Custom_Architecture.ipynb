{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Architectures\n",
    "\n",
    "The aim of this tutorial script is to show, how you can integrate your own neural network architectures into the MIScnn pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIScnn Pipeline\n",
    "\n",
    "As explained in more detail in the wiki, we need 4 core components in the pipeline:\n",
    "- Data I/O  \n",
    "- Data Augmentation (optional)\n",
    "- Preprocessor\n",
    "- Neural Network Model\n",
    "\n",
    "These classes handle all required steps for medical image segmentation and can be extensively customized. All classes, except the Data Augmentation class, use switchable interfaces which results into high configurability and offers simple integration of user-defined solutions.\n",
    "\n",
    "For our custom model, only the Neural Network class will be interesting for us. Before we can start, let's initialize a little testing pipeline in which we can deploy our custom architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from miscnn import Data_IO, Preprocessor, Neural_Network\n",
    "from miscnn.data_loading.interfaces import Dictionary_interface\n",
    "import numpy as np\n",
    "\n",
    "# Create 2D testing data set (grayscale image with binary mask)\n",
    "dataset2D = dict()\n",
    "for i in range(0, 100):\n",
    "    img = np.random.rand(16, 16) * 255\n",
    "    img = img.astype(int)\n",
    "    seg = np.random.rand(16, 16) * 2\n",
    "    seg = seg.astype(int)\n",
    "    dataset2D[\"TEST.sample_\" + str(i)] = (img, seg)\n",
    "    \n",
    "# Initialize Dictionary IO Interface\n",
    "io_interface2D = Dictionary_interface(dataset2D, classes=2, three_dim=False)\n",
    "\n",
    "# Create the Data I/O object\n",
    "data_io = Data_IO(io_interface2D, input_path=\"\")\n",
    "\n",
    "# Create and configure the Preprocessor class\n",
    "pp = Preprocessor(data_io, data_aug=None, batch_size=2, analysis=\"fullimage\")\n",
    "\n",
    "# Get sample list\n",
    "sample_list = data_io.get_indiceslist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Class\n",
    "\n",
    "After we successfully setup our dummy pipeline, we can have a closer look on the Neural Network class.\n",
    "\n",
    "This class provides functionality for handling all model methods. This class runs the whole pipeline and uses a Preprocessor instance to obtain batches.\n",
    "With an initialized Neural Network model instance, it is possible to run training, prediction and evaluations.\n",
    "\n",
    "The core function of the Neural Network class is to define the model architecture and its loss function for training. By default, the Neural Network class uses a standard U-Net architecture and the Tversky loss function. \n",
    "\n",
    "Before we begin with our custom architecture, let's have a look on the Neural Network architecture parameter and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard U-Net architecture\n",
    "from miscnn.neural_network.architecture.unet import UNet_standard\n",
    "\n",
    "# Initialize the imported standard U-Net architecture\n",
    "current_architecture = UNet_standard()\n",
    "\n",
    "# Create a deep learning neural network model with a standard U-Net architecture\n",
    "nn = Neural_Network(preprocessor=pp, architecture=current_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 2 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 2 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 590080      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 2 1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 5 1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 5 2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 5 2359808     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 5 2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, None, None, 2 524544      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 5 0           conv2d_transpose[0][0]           \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 590080      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 2 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, None, None, 1 131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 2 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 1 295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 1 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, None, None, 6 32832       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 1 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 6 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 6 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 36928       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, None, None, 3 8224        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 6 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 3 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 3 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 3 9248        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 3 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 2 66          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,771,330\n",
      "Trainable params: 7,765,442\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Output the model summary from Keras\n",
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Architecture\n",
    "\n",
    "Now, we can start implementing our custom architecture.\n",
    "\n",
    "MIScnn utilizes the subpackage Keras of Tensorflow for designing/defining architectures.\n",
    "Therefore, we have to use the Keras layers.\n",
    "\n",
    "You can find an extensive documentation of the Keras layers in the Tensorflow API:  \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "\n",
    "In order to create a new architecture, which is compatibile with MIScnn, it is required to create a architecture class. The architecture class has to contain the following three class functions:\n",
    "\n",
    "\n",
    "```\n",
    "class Abstract_Architecture():\n",
    "    __init__                Object initialization function\n",
    "    create_model_2D:        Creating a 2D Keras model (for 2D data)\n",
    "    create_model_3D:        Creating a 3D Keras model (for 3D data)\n",
    "```\n",
    "\n",
    "In Python code, our custom architecture class will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "\n",
    "# My Architecture Class\n",
    "class My_Architecture(Abstract_Architecture):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        return None\n",
    "    \n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your dataset (settings of your Data IO interface), MIScnn will call the create_model_2D or create_model_3D function to obtain the corresponding model.\n",
    "\n",
    "The __init__ function will be called by yourself when setting up the pipeline (Exactly as we did it previously with the imported standard U-Net). This gives you the opportunity to pass your own variables into your architecture class. A common use case would be to implement boolean tags if you want to include dropout or batch normalization layers in your architecture.  \n",
    "BUT: This is all optional. In our example, we don't specify anything init function, because you probably won't need it.\n",
    "\n",
    "So, let's start with creating a custom architecture. Due to our dataset is 2D, we only need a 2D architecture.  \n",
    "Therefore, we just fill the create_model_2D function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "from miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "# My Architecture Class\n",
    "class My_Architecture(Abstract_Architecture):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def create_model_2D(self, input_shape, n_labels=2):\n",
    "        # Define Input Layer\n",
    "        input_layer = Input(input_shape)\n",
    "\n",
    "        # Define some architecture\n",
    "        convE = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "        convE = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(convE)\n",
    "        poolE = MaxPooling2D(pool_size=(2, 2))(convE)\n",
    "\n",
    "        convM = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(poolE)\n",
    "        convM = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(convM)\n",
    "\n",
    "        convT = Conv2DTranspose(64, 3, strides=(2, 2), padding=\"same\")(convM)\n",
    "        convD = concatenate([convT, convE])\n",
    "        convD = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(convD)\n",
    "        convD = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(convD)\n",
    "\n",
    "        # Define Output Layer\n",
    "        output_layer = Conv2D(n_labels, (1,1), padding=\"same\", activation=\"softmax\")(convD)\n",
    "\n",
    "        # Define Keras Model (associated with input and output layers)\n",
    "        model = Model(inputs=[input_layer], outputs=[output_layer])\n",
    "        \n",
    "        # Return the model to the pipeline\n",
    "        return model\n",
    "\n",
    "    def create_model_3D(self, input_shape, n_labels=2):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware to watch out that the last tensor (output_layer) has the same dimension on the last axis as the number of classes (n_labels) in your segmentation dataset.  \n",
    "For example, if we have a 2D segmentation with 10 classes the output shape must be: (x, y, 10)\n",
    "\n",
    "Congratulations. That's it!\n",
    "We have successfully created a custom architecture for MIScnn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom Architecture\n",
    "\n",
    "Now, let's use our new custom architecture by integrating it in the MIScnn pipeline.  \n",
    "The proceeding to load the model is identical as before with the imported standard U-Net architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our new architecture\n",
    "new_architecture = My_Architecture()\n",
    "\n",
    "# Create a deep learning neural network model with our custom architecture\n",
    "nn = Neural_Network(preprocessor=pp, architecture=new_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 6 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 1 147584      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, None, None, 6 73792       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 1 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 2 130         conv2d_24[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 443,650\n",
      "Trainable params: 443,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Output the model summary from Keras\n",
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.0219 - dice_soft: 0.4890\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9835 - dice_soft: 0.5082\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9713 - dice_soft: 0.5144\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9603 - dice_soft: 0.5198\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.9591 - dice_soft: 0.5205\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.9527 - dice_soft: 0.5237\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9345 - dice_soft: 0.5328\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9177 - dice_soft: 0.5412\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.9021 - dice_soft: 0.5489\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.8906 - dice_soft: 0.5547\n"
     ]
    }
   ],
   "source": [
    "# Start training the model\n",
    "nn.train(sample_list, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Words\n",
    "\n",
    "Here, I presented the workflow of integrating custom architectures into the MIScnn pipeline.  \n",
    "I hope to give you an intention on how MIScnn works and how you can integrate/use MIScnn in your research projects.\n",
    "\n",
    "For further questions or suggestions, please do not hesitate to get in contact with me.  \n",
    "Also, if you want to contribute to MIScnn do not hesitate! :)\n",
    "\n",
    "Thanks for reading,  \n",
    "Dominik Müller"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
